{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CS 4501 - Digital Signal Processing**\n",
    "\n",
    "Phyl Peng (hp9psb), Brian Mbogo (bpm4pkz), Anna Williamson (amw4uet)\n",
    "\n",
    "*Image filter design for different noise distributions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: A neural network to classify the noise distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koehrsen, W. (2018). Transfer Learning with Convolutional Neural Networks in PyTorch. Towards Data Science. https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.resnet import Bottleneck\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "from scipy.fft import ifft2\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# salt and pepper\n",
    "from scipy import signal\n",
    "from statistics import median\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of data\n",
    "datadir = os.path.curdir\n",
    "traindir = os.path.join(datadir, 'train')\n",
    "validdir = os.path.join(datadir, 'valid') \n",
    "testdir = os.path.join(datadir, 'valid') #validation set = testing set for simplicity\n",
    "\n",
    "save_file_name = os.path.join(datadir, 'noise-model.pt')\n",
    "checkpoint_path = os.path.join(datadir, 'noise-model.pth')\n",
    "model_str = \"inception\"\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "vgg_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                            [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # Test does not use augmentation\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "inception_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(342),\n",
    "        #transforms.RandomRotation(degrees=30),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=299),  # Inception-specific\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                            [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=342),\n",
    "        transforms.CenterCrop(size=299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # Test does not use augmentation\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=342),\n",
    "        transforms.CenterCrop(size=299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_transforms = vgg_transforms if model_str == \"vgg\" else inception_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seed = 12600\n",
    "torch.random.manual_seed(model_seed)\n",
    "train_on_gpu = cuda.is_available()\n",
    "# Datasets from each folder\n",
    "data = {\n",
    "    'train':\n",
    "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
    "    'val':\n",
    "    datasets.ImageFolder(root=validdir, transform=image_transforms['val']),\n",
    "    'test':\n",
    "    datasets.ImageFolder(root=testdir, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "# Dataloader iterators\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], sampler=RandomSampler(data['train'], num_samples=200), batch_size=batch_size),\n",
    "    'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
    "}\n",
    "\n",
    "n_classes = len(data['train'].classes)\n",
    "print(f\"n_classes: {n_classes} \\n {data['train'].classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainiter = iter(dataloaders['train'])\n",
    "features, labels = next(trainiter)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_example = features[labels == 1][0, 0] #salt and pepper\n",
    "ga_example = features[labels == 0][0, 0] #gaussian\n",
    "plt.imshow(sp_example)\n",
    "plt.figure()\n",
    "plt.imshow(ga_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(model_name):\n",
    "  model = None\n",
    "  if model_name == \"vgg16\":\n",
    "    model = models.vgg16(pretrained=True)\n",
    "\n",
    "    # Freeze early layers\n",
    "    for param in model.parameters():\n",
    "      param.requires_grad = False\n",
    "    \n",
    "    #enable last 2 convolution layers\n",
    "    fl = len(model.features)\n",
    "    for layer in model.features[fl-6:fl]:\n",
    "      for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    #prepend transform layer to normalize fft channels\n",
    "    model.features[0] = torch.nn.Sequential(\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    model.features[0]\n",
    "  )\n",
    "    \n",
    "    #enable other fully-connected layers\n",
    "    for layer in model.classifier[1:]:\n",
    "      for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    n_inputs = model.classifier[6].in_features\n",
    "\n",
    "    # Add on classifier\n",
    "    model.classifier[6] = nn.Sequential(\n",
    "        nn.Linear(n_inputs, 256), nn.ReLU(),\n",
    "        nn.Linear(256, n_classes), nn.Softmax(dim=1))\n",
    "    \n",
    "  elif model_name == \"inceptionv3\":\n",
    "    model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze early layers\n",
    "    for param in model.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "    #prepend transform layer to normalize fft channels\n",
    "    model.Conv2d_1a_3x3 = torch.nn.Sequential(\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    model.Conv2d_1a_3x3\n",
    ")\n",
    "    #enable last inception layer (features)\n",
    "    for param in model.Mixed_7c.parameters():\n",
    "      param.requires_grad = True\n",
    "\n",
    "    model.fc = nn.Sequential(\n",
    "      nn.Linear(model.fc.in_features, 1024), nn.ReLU(),\n",
    "      nn.Linear(1024, n_classes), nn.Softmax(dim=1))\n",
    "\n",
    "  # Move to gpu and parallelize\n",
    "  if train_on_gpu:\n",
    "      model = model.to('cuda')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_pretrained_model(\"inceptionv3\")\n",
    "print(summary(\n",
    "        model, input_size=(3, 224, 224), batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get numerical value of each classification\n",
    "model.class_to_idx = data['train'].class_to_idx\n",
    "model.idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in model.class_to_idx.items()\n",
    "}\n",
    "\n",
    "print(list(model.idx_to_class.items()))\n",
    "\n",
    "trainiter = iter(dataloaders['train'])\n",
    "features, labels = next(trainiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          model_type=\"vgg\",\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=20,\n",
    "          print_every=2):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        model_type (str either vgg or inception)\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        model.train()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "            #print(f\"batch {ii}\")\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #use fft in the other channels of the image\n",
    "            imfft = ifft2(data[0, 0].numpy())\n",
    "            data[0, 1] = torch.tensor(np.real(imfft))\n",
    "            data[0, 2] = torch.tensor(np.imag(imfft))\n",
    "\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            output = model(data)\n",
    "            if model_type==\"inception\":\n",
    "              output = output[0]\n",
    "\n",
    "            # Loss and backpropagation of gradients\n",
    "            output = output[:, 1]\n",
    "            loss = criterion(output, target.float())\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track train loss by multiplying average loss by number of examples in batch\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            pred = torch.round(output)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            # Need to convert correct tensor from int to float to average\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            # Multiply average accuracy times the number of examples in batch\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            # Track training progress\n",
    "            #print(\n",
    "            #    f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "            #    end='\\r')\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    imfft = ifft2(data[0, 0].numpy())\n",
    "                    data[0, 1] = torch.tensor(np.real(imfft))\n",
    "                    data[0, 2] = torch.tensor(np.imag(imfft))\n",
    "\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    output = model(data)\n",
    "                    output = output[:, 1]\n",
    "                    loss = criterion(output, target.float())\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    pred = torch.round(output)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        #print(\n",
    "                        #    f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        #)\n",
    "\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train loss', 'valid loss', 'train acc',\n",
    "                                'valid acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "    #print(\n",
    "    #    f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    #)\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train loss', 'valid loss', 'train acc', 'valid acc'])\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['val'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=15,\n",
    "    model_type=model_str,\n",
    "    print_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Filters to perform denoising by noise distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/philpeng/Documents/image-denoising/guassian_bridge.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-248ee189c67c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# load image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"/Users/philpeng/Documents/image-denoising/guassian_bridge.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[0mpx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"guassian_bridge.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2766\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/philpeng/Documents/image-denoising/guassian_bridge.jpg'"
     ]
    }
   ],
   "source": [
    "# Gaussian Filter - used to remove noise and detail\n",
    "\n",
    "\n",
    "'''\n",
    "SOURCES:\n",
    "\n",
    "https://www.cs.auckland.ac.nz/courss/compsci373s1c/PatricesLectures/Image%20Filtering.pdf\n",
    "https://blog.en.uwa4d.com/2022/08/11/screen-post-processing-effects-chapter-1-basic-algorithm-of-gaussian-blur-and-its-implementation/\n",
    "https://en.wikipedia.org/wiki/Salt-and-pepper_noise\n",
    "https://www.geeksforgeeks.org/python-pil-getpixel-method/\n",
    "https://stackoverflow.com/questions/52307290/what-is-the-difference-between-images-in-p-and-l-mode-in-pil#:~:text=If%20you%20have%20an%20L,stores%20a%20greyscale%2C%20not%20colour.\n",
    "https://ijesc.org/upload/a2d11768dad7f56db1cc12bb3650879a.A%20Comparison%20of%20Salt%20and%20Pepper%20Noise%20Removal%20Filters.pdf\n",
    "https://www.geeksforgeeks.org/python-pil-copy-method/\n",
    "'''\n",
    "\n",
    "'''\n",
    "NOTES:\n",
    "\n",
    "- \"An effective noise reduction method for this type of noise is a median filter or a morphological filter.\"\n",
    "- first attempt: median filter\n",
    "- note: images are in \"L\"-mode... maps to black and white pixels/greyscale\n",
    "- a median filter is the best of a variety of filters to handle salt and pepper noise\n",
    "'''\n",
    "\n",
    "def convolution2DPadded(px, width, height, gaussian_kernel, ks_w, ks_h):\n",
    "    pad_x = ks // 2\n",
    "    pad_y = ks // 2\n",
    "    input_padded = np.pad(px, ((pad_x, pad_x), (pad_y, pad_y)), mode='constant')\n",
    "        \n",
    "    # Convolve the padded matrix with the Gaussian kernel\n",
    "    return convolve2d(input_padded, gaussian_kernel, mode='valid')\n",
    "    \n",
    "def gaussianDiscrete2D(theta, x, y):\n",
    "    g = 0\n",
    "    for ySubPixel in [i * 0.1 for i in range(int(y - 0.5 * 10), int(y + 0.6 * 10))]:\n",
    "        for xSubPixel in [i * 0.1 for i in range(int(x - 0.5 * 10), int(x + 0.6 * 10))]:\n",
    "            g += ((1 / (2 * math.pi * theta * theta)) *\n",
    "                  math.pow(math.e, -(xSubPixel * xSubPixel + ySubPixel * ySubPixel) / (2 * theta * theta)))\n",
    "    g /= 121\n",
    "    return g\n",
    "\n",
    "def gaussian2D(theta, size):\n",
    "    kernel = [[0 for i in range(size)] for j in range(size)]\n",
    "    for j in range(size):\n",
    "        for i in range(size):\n",
    "            kernel[i][j] = gaussianDiscrete2D(theta, i - (size / 2), j - (size / 2))\n",
    "\n",
    "    kernel_sum = sum([sum(row) for row in kernel])\n",
    "\n",
    "    kernel = [[element / kernel_sum for element in row] for row in kernel]\n",
    "    return kernel\n",
    "\n",
    "def smooth(px, width, height, ks, theta):\n",
    "    gaussian_kernel = gaussian2D(theta, ks)\n",
    "    print(px.shape)\n",
    "    output = convolution2DPadded(px, width, height, gaussian_kernel, ks, ks)\n",
    "    return output\n",
    "\n",
    "def smooth_image(px, w, h, ks, theta):\n",
    "    input_2d = [[0 for i in range(w)] for j in range(h)]\n",
    "    output_1d = [0 for i in range(w * h)]\n",
    "    output_2d = [[0 for i in range(w)] for j in range(h)]\n",
    "    output = [0 for i in range(w * h)]\n",
    "\n",
    "#     for j in range(h):\n",
    "#         for i in range(w):\n",
    "#             input_2d[j][i] = Image.new('RGB', (1, 1), px[j * w + i]).convert('L').getpixel((0, 0))\n",
    "    \n",
    "    output_2d = smooth(px, w, h, ks, theta)\n",
    "    print(len(output_1d))\n",
    "    print(output_2d.shape)\n",
    "#     for j in range(h):\n",
    "#         for i in range(w):\n",
    "#             output_1d[j * w + i] = output_2d[j][i]\n",
    "\n",
    "#     for i in range(len(output_1d)):\n",
    "#         grey = round(output_1d[i])\n",
    "#         if grey > 255:\n",
    "#              grey = 255\n",
    "#         if grey < 0:\n",
    "#             grey = 0\n",
    "#         output[i] = Image.new('L', (1, 1), (grey)).getpixel((0, 0))\n",
    "\n",
    "    return Image.fromarray(np.uint8(output_2d), 'L')\n",
    "\n",
    " \n",
    "# load image\n",
    "im = Image.open(r\"/Users/philpeng/Documents/image-denoising/guassian_bridge.jpg\")\n",
    "px = imread(\"guassian_bridge.jpg\")\n",
    "\n",
    "w, h = px.shape\n",
    "print(\"Original photo:\")\n",
    "display(im)\n",
    "original_im = im.copy()\n",
    "\n",
    "# filter image\n",
    "print(\"Gaussian blurred photo:\")\n",
    "ks = 5\n",
    "im = smooth_image(px, w, h, ks, 0.9)\n",
    "display(im)\n",
    "\n",
    "\n",
    "#print(\"Mean Squared Error:\", MSE(original_im, im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salt and Pepper Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saltpepper_car.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-04d04bb9af6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mimc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"saltpepper_seagull.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mimsp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mima\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimsp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2766\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saltpepper_car.jpg'"
     ]
    }
   ],
   "source": [
    "# function for calculating the MSE (Mean Squared Error) between two images\n",
    "# Source: https://www.statology.org/mean-squared-error-python/\n",
    "\n",
    "def MSE(actual_im, predict_im):\n",
    "    mse = np.square(np.subtract(actual_im, predict_im)).mean() \n",
    "    return mse\n",
    "\n",
    "# initialize the image to filter\n",
    "\n",
    "ima = r\"saltpepper_car.jpg\"\n",
    "imb = r\"saltpepper_hiking.jpg\"\n",
    "imc = r\"saltpepper_seagull.jpg\"\n",
    "\n",
    "imsp = Image.open(ima)\n",
    "display(imsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Filter - used to remove salt and pepper noise\n",
    "\n",
    "\n",
    "'''\n",
    "SOURCES:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Salt-and-pepper_noise\n",
    "https://www.cs.auckland.ac.nz/courss/compsci373s1c/PatricesLectures/Image%20Filtering.pdf\n",
    "https://www.geeksforgeeks.org/python-pil-getpixel-method/\n",
    "https://stackoverflow.com/questions/52307290/what-is-the-difference-between-images-in-p-and-l-mode-in-pil#:~:text=If%20you%20have%20an%20L,stores%20a%20greyscale%2C%20not%20colour.\n",
    "https://ijesc.org/upload/a2d11768dad7f56db1cc12bb3650879a.A%20Comparison%20of%20Salt%20and%20Pepper%20Noise%20Removal%20Filters.pdf\n",
    "https://www.geeksforgeeks.org/python-pil-copy-method/\n",
    "'''\n",
    "\n",
    "'''\n",
    "NOTES:\n",
    "\n",
    "- \"An effective noise reduction method for this type of noise is a median filter or a morphological filter.\"\n",
    "- first attempt: median filter\n",
    "- note: images are in \"L\"-mode... maps to black and white pixels/greyscale\n",
    "- a median filter is the best of a variety of filters to handle salt and pepper noise\n",
    "'''\n",
    "\n",
    "\n",
    "def median_pixel(width, height, w, h, px):\n",
    "    if (w != 0 and w != width-1 and h != 0 and h != height-1): # don't compute the edges\n",
    "        px[w, h] = median([px[w, h+1], px[w, h-1], px[w+1, h], px[w-1, h], px[w-1, h-1], px[w+1, h-1], px[w+1, h+1], px[w-1, h+1], px[w, h]])\n",
    "    return\n",
    "\n",
    "\n",
    "def median_filter(im):\n",
    "    px = im.load()\n",
    "    width, height = im.size\n",
    "    for w in range(0, width):\n",
    "        for h in range(0, height):\n",
    "            median_pixel(width, height, w, h, px)\n",
    "    return\n",
    "\n",
    "original1 = imsp.copy()\n",
    "\n",
    "# load image\n",
    "print(\"Original photo:\")\n",
    "display(original1)\n",
    "\n",
    "# filter image\n",
    "print(\"Median filtered photo:\")\n",
    "median_filter(original1)\n",
    "display(original1)\n",
    "\n",
    "print(\"Mean Squared Error:\", MSE(imsp, original1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Filter - used to sharpen edges/remove blurriness in an image\n",
    "\n",
    "'''\n",
    "SOURCES:\n",
    "\n",
    "https://www.youtube.com/watch?v=kewse-JsjH0\n",
    "https://www.geeksforgeeks.org/laplacian-filter-using-matlab/\n",
    "https://www.pluralsight.com/guides/importing-image-data-into-numpy-arrays\n",
    "https://www.l3harrisgeospatial.com/docs/laplacianfilters.html#:~:text=Laplacian%20filter%20kernels%20usually%20contain,be%20either%20negative%20or%20positive.\n",
    "https://www.geeksforgeeks.org/image-sharpening-using-laplacian-filter-and-high-boost-filtering-in-matlab/\n",
    "'''\n",
    "\n",
    "def sharpen_edges(im, new_image, mult):\n",
    "    data_im = asarray(im)\n",
    "    data_newimage = asarray(new_image)\n",
    "    sharp_image = Image.fromarray(abs(data_im + (mult)*data_newimage))\n",
    "    return sharp_image\n",
    "\n",
    "def apply_laplacian(im, kernel):\n",
    "    data = asarray(im) # load image as a 2d array\n",
    "    new = signal.convolve2d(data, kernel, boundary='symm', mode='same')\n",
    "    new_image = Image.fromarray(abs(new))\n",
    "    return new_image\n",
    "\n",
    "# copy images with median filter already applied\n",
    "denoised_image1 = original1.copy()\n",
    "denoised_image2 = original1.copy()\n",
    "\n",
    "kernel1 = [[0, 1, 0], [1, -4, 1], [0, 1, 0]]\n",
    "new_image1 = apply_laplacian(denoised_image1, kernel1)\n",
    "print(\"1 Laplacian filtered photo - outline edges (kernel 1)\")\n",
    "new_image1.show() # need to use show()! Using display() won't work here\n",
    "sharp_im1 = sharpen_edges(denoised_image1, new_image1, -1)\n",
    "print(\"2 Laplacian filtered photo (kernel 1)\")\n",
    "sharp_im1.show()\n",
    "\n",
    "print(\"Mean Squared Error (kernel 1):\", MSE(imsp, sharp_im1))\n",
    "\n",
    "kernel2 = [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]\n",
    "new_image2 = apply_laplacian(denoised_image2, kernel2)\n",
    "print(\"3 Laplacian filtered photo - outline edges (kernel 2)\")\n",
    "new_image2.show() # need to use show()! Using display() won't work here\n",
    "sharp_im2 = sharpen_edges(denoised_image2, new_image2, 1)\n",
    "print(\"4 Laplacian filtered photo (kernel 2)\")\n",
    "sharp_im2.show()\n",
    "\n",
    "print(\"Mean Squared Error (kernel 2):\", MSE(imsp, sharp_im2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edited version of a Noise Adaptive Fuzzy Switching Median filter (NAFSM) - used to remove salt and pepper noise \n",
    "# while maintaining sharp edges/prevent blurring of the original photo\n",
    "\n",
    "'''\n",
    "SOURCES:\n",
    "\n",
    "https://ieeexplore.ieee.org/document/5356178\n",
    "https://stackoverflow.com/questions/39554660/np-arrays-being-immutable-assignment-destination-is-read-only\n",
    "'''\n",
    "\n",
    "'''\n",
    "NOTES:\n",
    "\n",
    "The below implementation is an edited version of the Noise Adaptive Fuzze Switching Median Filter (NAFSM) described in\n",
    "the paper linked above. The major difference is the method for determining the new value of a salt and pepper pixel.\n",
    "The paper provided an algorithm using various constants (and little substantiation for the values of these constants)\n",
    "which led to a subpar filtering result. By switching out this custom algorithm and using the median value of the\n",
    "surrounding pixels (excluding other salt and pepper pixels) to determine the value of the current salt and pepper pixel\n",
    "led to a better result. \n",
    "'''\n",
    "\n",
    "def check_G(data_im, noise_mask, w, h):\n",
    "    width, height = noise_mask.shape\n",
    "    sum_N = 0\n",
    "    N_one_list = []\n",
    "    luminance_diff = []\n",
    "    for m in range(-1, 2):\n",
    "        for n in range(-1, 2):\n",
    "            if ((w+m) >= 0 and (h+n) >= 0 and (w+m) < width and (h+n) < height):\n",
    "                if (noise_mask[w+m][h+n] == 1):\n",
    "                    N_one_list.append(data_im[w+m][h+n])\n",
    "                    sum_N += 1\n",
    "                if (m != 0 and n != 0):\n",
    "                    luminance_diff.append(abs(int(data_im[w+m][h+n]) - int(data_im[w][h])))\n",
    "                \n",
    "    max_luminance_diff = max(luminance_diff)\n",
    "    # values given by the paper\n",
    "    T_1 = 10\n",
    "    T_2 = 30\n",
    "    if (max_luminance_diff < T_1):\n",
    "        F = 1 # here\n",
    "    elif (max_luminance_diff >= T_2):\n",
    "        F = 1\n",
    "    else:\n",
    "        F = (max_luminance_diff - T_1) / (T_2 - T_1)\n",
    "    return sum_N, N_one_list, F\n",
    "\n",
    "def NAFSM_filter(im, noise_mask, use_median):\n",
    "    original_im = asarray(im)\n",
    "    data_im = original_im.copy()\n",
    "    width, height = data_im.shape\n",
    "    \n",
    "    for w in range(0, width):\n",
    "        for h in range(0, height):\n",
    "            if (noise_mask[w][h] == 0):\n",
    "                sum_N, N_one_list, F = check_G(data_im, noise_mask, w, h)\n",
    "                if (sum_N >= 1):\n",
    "                    if (use_median):\n",
    "                        data_im[w][h] = np.median(N_one_list)\n",
    "                    else:\n",
    "                        data_im[w][h] = (1-F)*data_im[w][h] + F*median(N_one_list) # calculate median, excluding surrounding salt&pepper pixels\n",
    "    return data_im\n",
    "\n",
    "def detection(im):\n",
    "    data_im = asarray(im)\n",
    "    # note: strangely, using asarray() flips the width and height of the original image when converting to array\n",
    "    width, height = data_im.shape\n",
    "    \n",
    "    L_salt = 255\n",
    "    L_pepper = 0\n",
    "    \n",
    "    # N(i,j)=1  represents \"noise-free pixels\"\n",
    "    # N(i,j)=0  represents \"noise pixels\"\n",
    "    noise_mask = np.ones((width, height))\n",
    "    \n",
    "    for w in range(0, width):\n",
    "        for h in range(0, height):\n",
    "            if (data_im[w][h] < 20 or data_im[w][h] > 235):\n",
    "                noise_mask[w][h] = 0 # noise pixel identified\n",
    "    return noise_mask\n",
    "\n",
    "original2 = imsp.copy()\n",
    "noise_mask = detection(original2)\n",
    "data_result = NAFSM_filter(original2, noise_mask, True)\n",
    "final_result = Image.fromarray(data_result)\n",
    "print(\"Noise adaptive fuzzy switching median filter - adapted to use median filter\")\n",
    "final_result.show()\n",
    "print(\"Mean Squared Error:\", MSE(imsp, final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of novel image-denoising technique Elastic Median Filter 1 and 2 (EMF1) (EMF2)\n",
    "\n",
    "'''\n",
    "SOURCES:\n",
    "\n",
    "https://www.researchgate.net/publication/299474315_Two_new_methods_for_removing_salt-and-pepper_noise_from_digital_images\n",
    "'''\n",
    "\n",
    "def med_pixel(width, height, w, h, px):\n",
    "    if (w != 0 and w != width-1 and h != 0 and h != height-1):\n",
    "        px_list = [px[w, h+1], px[w, h-1], px[w+1, h], px[w-1, h], px[w-1, h-1], px[w+1, h-1], px[w+1, h+1], px[w-1, h+1], px[w, h]]\n",
    "        med_val = np.median(px_list)\n",
    "        return med_val\n",
    "    return -1\n",
    "\n",
    "def diff_pixels(width, height, w, h, px):\n",
    "    if (w != 0 and w != width-1 and h != 0 and h != height-1):\n",
    "        px_list = [px[w, h+1], px[w, h-1], px[w+1, h], px[w-1, h], px[w-1, h-1], px[w+1, h-1], px[w+1, h+1], px[w-1, h+1], px[w, h]]\n",
    "        med_val = np.median(px_list)\n",
    "        sum_diff = 0\n",
    "        for each in px_list:\n",
    "            sum_diff += np.abs(med_val - each)\n",
    "        return sum_diff, med_val\n",
    "    return -1, -1\n",
    "\n",
    "\n",
    "def EMF1(im, beta):\n",
    "    px = im.load()\n",
    "    width, height = im.size\n",
    "    alpha = (3*3)**beta\n",
    "    \n",
    "    for w in range(0, width):\n",
    "        for h in range(0, height):\n",
    "            sum_diff, med_val = diff_pixels(width, height, w, h, px)\n",
    "            if (sum_diff != -1 and med_val != -1):\n",
    "                comp_plus = med_val + alpha + np.sqrt(sum_diff)\n",
    "                comp_minus = med_val - alpha - np.sqrt(sum_diff)\n",
    "                if (px[w, h] >= comp_plus or px[w, h] <= comp_minus):\n",
    "                    px[w, h] = int(med_val)\n",
    "    return \n",
    "\n",
    "def EMF2(im, beta):\n",
    "    px = im.load()\n",
    "    width, height = im.size\n",
    "    alpha = (3*3)**beta\n",
    "    \n",
    "    for w in range(0, width):\n",
    "        for h in range(0, height):\n",
    "            med_val = med_pixel(width, height, w, h, px)\n",
    "            if (med_val != -1):\n",
    "                comp_plus = med_val + alpha\n",
    "                comp_minus = med_val - alpha\n",
    "                if (px[w, h] >= comp_plus or px[w, h] <= comp_minus):\n",
    "                    px[w, h] = int(med_val)\n",
    "    return\n",
    "\n",
    "\n",
    "# load image\n",
    "original3 = imsp.copy()\n",
    "comp_im = original3.copy()\n",
    "original_im = original3.copy()\n",
    "print(\"Original photo:\")\n",
    "display(original3)\n",
    "\n",
    "# smaller beta value - less salt and pepper pixels, but blurrier?\n",
    "beta = 1.0\n",
    "\n",
    "print(\"EMF1:\")\n",
    "EMF1(original3, beta)\n",
    "display(original3)\n",
    "print(\"Mean Squared Error (EMF1):\", MSE(comp_im, original3))\n",
    "\n",
    "print(\"EMF2:\")\n",
    "EMF2(original_im, beta)\n",
    "display(original_im)\n",
    "print(\"Mean Squared Error (EMF2):\", MSE(comp_im, original_im))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
